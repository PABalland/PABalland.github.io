writeLines(all, paste0("treemap-", i, ".html"))
}
setwd("D:/Dropbox/2-private/2-bif/1_crypto/2-treemaps")
writeLines(all, paste0("treemap-", i, "-", y, ".html"))
writeLines(all, paste0("treemap-", i, ".html"))
# write for printing
dft$color = "white"
p2 = toJSON(dft)
all = paste (p1, p2, p3, collapse="\n")
setwd("D:/Dropbox/2-private/2-bif/1_crypto/2-treemaps")
writeLines(all, paste0("treemap-", i, "-white-", y, ".html"))
}
# argon
# balt
#
#url <- paste0("https://bscscan.com/tokenholdings?a=0x0392957571f28037607c14832d16f8b653edd472")
#response <- httr::GET(url)
#parsed <- jsonlite::fromJSON(httr::content(response, "text",
#                                          encoding = "UTF-8"))
#url <- paste0("https://bscscan.com/tx/0xa273ba63602ee22aab40bafc5530e28410b420e0057d1f79c5427122319b424a")
#response <- httr::GET(url)
#parsed <- jsonlite::fromJSON(httr::content(response, "text",
#                                          encoding = "UTF-8"))
#install.packages("rvest")
#library(rvest)
#simple <- read_html("https://bscscan.com/tx/0xa273ba63602ee22aab40bafc5530e28410b420e0057d1f79c5427122319b424a")
#forecasts <- read_html("https://forecast.weather.gov/MapClick.php?lat=37.7771&lon=-122.4196#.Xl0j6BNKhTY") %>%
#  html_nodes(".temp") %>%
#  html_text()
#forecasts
#forecasts <- read_html("https://bscscan.com/tx/0xa273ba63602ee22aab40bafc5530e28410b420e0057d1f79c5427122319b424a") %>%
# html_nodes(".mr-1") %>%
#  html_text()
#forecasts
#d = data.frame (trans.id = forecasts[3],
#     sold = forecasts[17],
#    coin.s = forecasts[19],
#     buy = forecasts[31],
#     coin.b = forecasts[33],
#  tr.fee = "?",
#  value = "?")
#forecasts <- read_html("https://bscscan.com/tx/0xa273ba63602ee22aab40bafc5530e28410b420e0057d1f79c5427122319b424a") %>%
#  html_nodes(".col-md-3") %>%
#  html_text()
#forecasts
### USING API
# bsc
# Hermosa
# s@auRkrat24=
# API key = Q4ITSZENR8ADEBYWMUGH8QDF7HTZIDRTZV
#api = "Q4ITSZENR8ADEBYWMUGH8QDF7HTZIDRTZV"
#address = "0x5bc37becf10bbbc67f98972dc1b24cb6887e8729"
#link = paste0("https://api.bscscan.com/api?module=account&action=txlist&address=",
#             address,
#            "&startblock=1&endblock=99999999&sort=asc&apikey=",
#           api)
#url <- link
#response <- httr::GET(url)
#parsed <- jsonlite::fromJSON(httr::content(response, "text",
#                                          encoding = "UTF-8"))
#df = parsed$result
#df$tr.fee.bnb = as.numeric(df$gasUsed)*
#               as.numeric(df$gasPrice)/1000000000000000000
# https://api.bscscan.com/api?module=account&action=txlist&address=0xa273ba63602ee22aab40bafc5530e28410b420e0057d1f79c5427122319b424a&startblock=1&endblock=99999999&sort=asc&apikey=Q4ITSZENR8ADEBYWMUGH8QDF7HTZIDRTZV
# https://api.bscscan.com/api?module=account&action=txlist&address=0x0000000000000000000000000000000000001004&startblock=1&endblock=99999999&sort=asc&apikey=YourApiKeyToken
# https://api.bscscan.com/api?module=account&action=balance&address=0xa273ba63602ee22aab40bafc5530e28410b420e0057d1f79c5427122319b424a&tag=latest&apikey=Q4ITSZENR8ADEBYWMUGH8QDF7HTZIDRTZV
# PAPER WALLETS
#1Gz2dxbFuv91oc73rvxtGkvHFrRXTbVRwm # 0.02 BTC
#15XHFHWuWsSrJwQcuLcDsfm1R7ZUWyjzQq
#1JsyNJNUqu8TD9HWgQChAmpLg5nhN6EMrn
#1C9joj9QMcULPjgk5pwAcZBWQtWNFmEtHp
#1KtzesnaTZba9RBaHfe1BoRE5nWdahzW9
#1KtzesnaTZba9RBaHfe1BoRE5nWdahzW9
#1FBrT9PLJswqiiLZ4X83bH8BDRW1kagbv8
#1PNBbeMrfGXXBBts178KvJA7M5HPc8K2bW
#178axHTzTZMkGRRdHBd7JXiWVSXrFKBHLj
#1BJuKYmorugtDZosGH7Q1akR6PUst7JenL
#1K1gWeqxRCikUV5udn1yerVPsGQYYW2r2m
#17FrPiX1c8hQ5696aAkE8W4pNoZ51j3Stp
#1A3dTgLTuTQRBDDjp3hFTBe9qC9BiCZNod
#1FpG6euKzC1r3t93TBPVcB1VxwLjBKuth9
#12w2Esi16eLUdXPaRMDJbNGnCmhhccC1jo
#1FabtRciobkScax56uXF1Y9cAMBQfJhprS
#14dVs79mbsFKAkqqHCiD5nd5MQY4sQfknc
#12sXyqbYtWcnuMfxnVPehyyjzPVc3jWJDe
#1Gtyg4Mb7sTHRk79DhfkQfwQuJasrBKm4u
#1vgUzCpP9rdLGKxRaCH44CSEvxMir7hdc
#12gLaTdKzEPvZAtmh3sXYtXFguFZtkYH86
#1LqkhFS1x5rEJfUhE7tETAgJHRq6YLbYeK
#1KWKpC1Fz6gzRK4A7qTQtg6VZR1Msqt3vL
#1nMFZx8zXTJkbseYN31VXy8kDzdE1BdmU
#1AFnABLuebbkjv5KpLHUocEVH3qivh2XvD
#1AaEgUj12UnJBCDxspmR9LRvaSYDxC839P
#1MwoDURZhdtfG6YUo6LMs6V69zSLK3xmzs
#13LRXLLbbEwvrSAU2h72DrrE3rd14QZtA8
#1Mo7f1ea4s4xJSDHqvSBsiqZwTLa5DtNRR
#1NUF1X1VxQrn8wwXQw2t8YAmHaaPEwPfyw
#1Addy1Gyx9jUXiTVCF123uWdoahFD3quSd
#15pWQUkq2uiRVZVXEtnKG2spVyeJ8fbg8p
#1CuEhjcnvGVDc3wUreWEvbg6b6YZNWFPNh
#168bF6L5CMz82v9r1EY1TqupkJov6CQjRh
#1Aby1mM5kzGiKXfSD9Astfio5q8dcKqCdf
#1vQnJ4DngLD3PDGPNpcFpkRH6dJDcZ2f5
#13TSBFPunv8RxtALVAPHXHELXBqHXt6opP
#19tyL11Rrbzy6QWnZ75CgHc8JXSyPkRkNE
#14DqfUDvJw5yjsAc5qbGXGKzgRU5HKyHHC
#1DRthGeuJyLffJHTRWGJRwJQfc6UjuPSM9
#1GM4TtsT9PkhntD4LSGJisadDBeYzsvZ1s
#1LyxJdFJVZwUj4eoPVeGozZvqnQPcHKkzz
# Lyn Alden research
# Pierre-Alex
# contact@argosgroup.net
# PA@tArgos31450=
# buying under our name - better corporation?
# $17.5
# due diligence: 30 days after signature (no exact date)
# Europ comm
# system31=brussels
# INVESTING.COM
# T@lalalala09=
# ca.investing.com-EUR-USD-Open
#Alf@3131=
#rubber solve prefer stomach scheme double tooth brass grain come hand thunder
# CR46015115520020082499 - PA CR
# - PA BNP
# - CE
# - Chase
# pa@argosgroup.net
# Alb@toRe321=
# 25/5/2021
# 80k BTC
# 80k ETH
# 40k BNB
# 10k NEXO/CAKE/UNI
# Imp loss formula
# see here: https://www.bscgateway.com/liquidity-pool-pancakeswap-return-strategies
p2p1 = 0.12 # 100% means no change at all: value of 100 in t1, and 100 in t2
# 80% p2p1 means -20% price change
IL = 100* ((2*sqrt(p2p1)/(1+p2p1))-1) #(in%)
# bought $100 of ETH and $100 of BTC
# ETH now worth 120 and BTC 100
# pool = 220 - you get 110/120 = 0.9166667 ETH and 1.1 BTC
# 0.9166667
p2p1 = 2 # 100% means no change at all: value of 100 in t1, and 100 in t2
IL = 100* ((2*sqrt(p2p1)/(1+p2p1))-1) #(in%)
# bought $100 of ETH and $100 of BTC
# BNP PA: FR7630004021050000061344938
# CE  PA: FR7613135000800463072604271
# Argos Digital ($): CR24015115520020082507 (BNCRCRSJ)
# chase
# chase
#Account holder name: Alexandre Balland
#Bank name: Chase
#Swift code: CHASUS33
#Routing number: 322271627
#Account number: 817622595
#Branch address: 10901 Wilshire Blvd, Los Angeles, CA 90024, USA
#Beneficiary's address: 24 Harbor View Street, Dorchester, MA, 02125-1328, United States of America
pa.julie = 5000 + # blockfi
500 + # zelle
1500 - # casa marbella
900 - # zelle reimb
3500 + # old smart contract
1200 +
2300 # new smart contract J
# note: macbook + billet BNC = 630 EUR 751 USD
# PA owe J btc + 2.3k usdc via SC
# J owe PA 6100
#julie.btc = 0.01844923 # 1034.14 USD
#julie.eth = 0.12968348 #
#1200
#bna.btc = 0.2775758
#bna.eth = 0.04222180 + # sold 55555 dent on binance for	0.04222180 ETH on 29/8
#0.2 + # sold 230 bat @ 0.35 USD and bought 0.20 ETH on CRO on 29/8
#0.25  # sold 482 ENJ @ 0.21 USD and bought 0.25 ETH on CRO on 29/8
bna.usdc = -323 # blockFi
# read nexo interests
setwd("D:/Dropbox/2-private/2-bif/1_crypto")
int = read.csv ("nexo_transactions.csv")
int = subset (int, int$Currency == "NEXONEXO")
# this is what belong to asg
sum(int$Amount)
tolower("SARCONA ALESSANDRO")
setwd("D:/Dropbox/2-private/PABalland.github.io/bernard-maris-chair/actors")
setwd("D:/Dropbox/2-private/1-asg/1-production/6-occitanie")
# setwd to latest RegPat version
dir = "D:/Dropbox/2-private/1-asg/1-production/6-occitanie"
setwd(paste0(dir))
options(stringsAsFactors=FALSE)
# setwd to latest RegPat version
dir = "D:/Dropbox/2-private/1-asg/1-production/6-occitanie"
dir.reg = "D:/Dropbox/2-private/1-asg/1-production/_DATA/PATENTS/REGPAT"
# load packages
library (data.table)
library (stringr)
library (dplyr)
# read cpc info
setwd(dir.reg)
cpc = fread ("pctnb-cpc.csv", sep = ",", header = T)
# read crosswalk
# outcome of the NLP/text mining process
setwd(paste0(dir, "/1-data"))
crosswalk = read.csv("crosswalk.csv", sep = ";", check.names = F)
colnames (crosswalk) = c("parent",	"priority",	"cpc",	"description")
crosswalk$cpc = str_trim(crosswalk$cpc) # remove white space
crosswalk$tail = str_sub(crosswalk$cpc,-3,-1) # remove tail /00
crosswalk$cpc[crosswalk$tail == "/00"] = gsub("/00","", crosswalk$cpc[crosswalk$tail == "/00"]) # remove tail /00
crosswalk$tail = NULL
# find child classification (and remove them to avoid counting duplicates)
# expl: if we have G02F2 we want to remove lower levels (child) such as G02F22
crosswalk$prio.cpc = paste0(crosswalk$priority, crosswalk$cpc)
crosswalk$parent.cpc = substr(crosswalk$prio.cpc, 0, nchar(crosswalk$prio.cpc)-1)
crosswalk$child = crosswalk$parent.cpc %in% crosswalk$prio.cpc
crosswalk = subset (crosswalk, crosswalk$child == FALSE)
crosswalk = crosswalk[, c("parent",	"priority",	"cpc",	"description")]
# create priority-patent id
# this is the most time consuming step
prio = NULL
for (i in unique (crosswalk$cpc)) {
sub = cpc
### code line below is slow (substr)
sub$cpc = substr(sub$cpc, 0, nchar(i)) # remove deeper classifications to match with higher levels (Y02P90/45 will be included in Y02P)
sub = sub[cpc == i] # subset
sub$cpc = crosswalk$priority[crosswalk$cpc==i]
prio = rbind (prio, sub)
}
prio = prio %>% distinct() # remove observations for same patent/cpc
colnames (prio) = c("pct_nbr", "priority")
setwd(paste0(dir))
write.csv (prio, "pctnb-prio.csv", row.names = F)
options(stringsAsFactors=FALSE)
# setwd to latest RegPat version
dir = "D:/Dropbox/2-private/1-asg/1-production/6-occitanie"
dir.reg = "D:/Dropbox/2-private/1-asg/1-production/_DATA/PATENTS/REGPAT"
# load packages
library (data.table)
library (stringr)
library (dplyr)
# read cpc info
setwd(dir.reg)
cpc = fread ("pctnb-cpc.csv", sep = ",", header = T)
# read crosswalk
# outcome of the NLP/text mining process
setwd(paste0(dir))
crosswalk = read.csv("crosswalk.csv", sep = ";", check.names = F)
colnames (crosswalk) = c("parent",	"priority",	"cpc",	"description")
crosswalk$cpc = str_trim(crosswalk$cpc) # remove white space
crosswalk$tail = str_sub(crosswalk$cpc,-3,-1) # remove tail /00
crosswalk$cpc[crosswalk$tail == "/00"] = gsub("/00","", crosswalk$cpc[crosswalk$tail == "/00"]) # remove tail /00
crosswalk$tail = NULL
# find child classification (and remove them to avoid counting duplicates)
# expl: if we have G02F2 we want to remove lower levels (child) such as G02F22
crosswalk$prio.cpc = paste0(crosswalk$priority, crosswalk$cpc)
crosswalk$parent.cpc = substr(crosswalk$prio.cpc, 0, nchar(crosswalk$prio.cpc)-1)
crosswalk$child = crosswalk$parent.cpc %in% crosswalk$prio.cpc
crosswalk = subset (crosswalk, crosswalk$child == FALSE)
crosswalk = crosswalk[, c("parent",	"priority",	"cpc",	"description")]
# create priority-patent id
# this is the most time consuming step
prio = NULL
for (i in unique (crosswalk$cpc)) {
sub = cpc
### code line below is slow (substr)
sub$cpc = substr(sub$cpc, 0, nchar(i)) # remove deeper classifications to match with higher levels (Y02P90/45 will be included in Y02P)
sub = sub[cpc == i] # subset
sub$cpc = crosswalk$priority[crosswalk$cpc==i]
prio = rbind (prio, sub)
}
prio = prio %>% distinct() # remove observations for same patent/cpc
colnames (prio) = c("pct_nbr", "priority")
setwd(paste0(dir))
write.csv (prio, "pctnb-prio.csv", row.names = F)
head(prio)
web = "D:/Dropbox/2-private/PABalland.github.io/bernard-maris-chair/actors"
dir  = "D:/Dropbox/2-private/1-asg/1-production/6-occitanie" # for analysis
dir.regpat = "D:/Dropbox/2-private/1-asg/1-production/_DATA/PATENTS/REGPAT" # for latest regpat version
web = "D:/Dropbox/2-private/PABalland.github.io/bernard-maris-chair/actors"
# read priorities
setwd(paste0(dir))
options(stringsAsFactors=FALSE)
library (jsonlite)
library (EconGeo)
library (RColorBrewer)
library (data.table)
library (dplyr)
dir  = "D:/Dropbox/2-private/1-asg/1-production/6-occitanie" # for analysis
dir.regpat = "D:/Dropbox/2-private/1-asg/1-production/_DATA/PATENTS/REGPAT" # for latest regpat version
web = "D:/Dropbox/2-private/PABalland.github.io/bernard-maris-chair/actors"
# load different parts of html
setwd("D:/Dropbox/2-private/1-asg/1-production/_SOURCE/treemaps")
p1 = paste(readLines("part-1.html"), collapse="\n") #before json data
p3 = paste(readLines("part-3-patents-assignee.html"), collapse="\n") #after json data
# read priorities
setwd(paste0(dir))
df = fread ("pctnb-prio.csv", sep = ",", header = T)
# read app info
setwd(dir.regpat)
app = fread ("pctnb-app-reg.csv", sep = ",", header = T)
app$ctry = substr(app$reg_code, 0, 2)
app = app %>% distinct ()
df = inner_join(df, app, by = "pct_nbr")
df$year = as.numeric(substr(df$pct_nbr, 3, 6))
df = subset (df, df$year >= 2017) # select period
df$year = NULL
df$freq = 1
df$ID = paste0(df$priority, df$app_name)
df$count = ave(df$freq, df$ID, FUN = sum)
df = df[, c("priority", "app_name", "count", "ctry")]
df = df %>% distinct ()
df$region = df$priority
df$sum = ave(df$count, df$priority, FUN = sum)
df$share = round (df$count*100/df$sum, digits = 2)
df$count.all = ave(df$count, df$app_name, FUN = sum)
df$sum.all = sum(df$count)
df$shareall = round (df$count.all*100/df$sum.all, digits = 2)
for (i in unique (df$region)) {
#i = "Head-up displays"
sub = subset (df, df$region == i)
sub$id = sub$app_name
sub$value = sub$count
sub$color = "lightblue"
sub$color[sub$ctry == "CN"] = "orange"
sub$color[sub$ctry == "US"] = "red"
sub$color[sub$ctry == "JP"] = "yellow"
sub$color[sub$ctry == "DE"] = "green"
sub$color[sub$ctry == "FR"] = "blue"
sub$color[sub$ctry == "KR"] = "lightgreen"
sub$color[sub$ctry == "UK"] = "lightred"
sub$color[sub$ctry == "SE"] = "lightorange"
sub$color[sub$ctry == "CA"] = "lightgrey"
sub$color[sub$ctry == "NL"] = "black"
sub$color[sub$ctry == "IL"] = "grey"
sub$parent = sub$ctry
sub$rca = 0
sub = unique(sub[,  c("parent", "id", "value", "color", "share", "rca", "shareall", "ctry")])
sub = sub[complete.cases(sub),]
p2 = toJSON(sub)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir, "/3-outputs/treemaps/assignees"))
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
writeLines(all, paste0(i, ".html"))
setwd(paste0(web, "/treemaps/assignees"))
writeLines(all, paste0(i, ".html"))
}
df = df[, c("priority", "app_name", "count")]
write.csv2(df, "inventors.csv", row.names = F)
df = subset (df, df$count>1)
setwd(paste0(dir, "/3-outputs/treemaps/assignees"))
dtdata1 <- datatable (df, filter = 'top')
DT::saveWidget(dtdata1, "inventors.html")
setwd(paste0(web, "/treemaps/assignees"))
DT::saveWidget(dtdata1, "inventors.html")
setwd(paste0(web))
library(DT)
for (i in unique (df$region)) {
#i = "Head-up displays"
sub = subset (df, df$region == i)
sub$id = sub$app_name
sub$value = sub$count
sub$color = "lightblue"
sub$color[sub$ctry == "CN"] = "orange"
sub$color[sub$ctry == "US"] = "red"
sub$color[sub$ctry == "JP"] = "yellow"
sub$color[sub$ctry == "DE"] = "green"
sub$color[sub$ctry == "FR"] = "blue"
sub$color[sub$ctry == "KR"] = "lightgreen"
sub$color[sub$ctry == "UK"] = "lightred"
sub$color[sub$ctry == "SE"] = "lightorange"
sub$color[sub$ctry == "CA"] = "lightgrey"
sub$color[sub$ctry == "NL"] = "black"
sub$color[sub$ctry == "IL"] = "grey"
sub$parent = sub$ctry
sub$rca = 0
sub = unique(sub[,  c("parent", "id", "value", "color", "share", "rca", "shareall", "ctry")])
sub = sub[complete.cases(sub),]
p2 = toJSON(sub)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir))
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
writeLines(all, paste0(i, ".html"))
setwd(paste0(web))
writeLines(all, paste0(i, ".html"))
}
df = df[, c("priority", "app_name", "count")]
write.csv2(df, "inventors.csv", row.names = F)
df = subset (df, df$count>1)
setwd(paste0(dir, "/3-outputs/treemaps/assignees"))
dtdata1 <- datatable (df, filter = 'top')
DT::saveWidget(dtdata1, "inventors.html")
setwd(paste0(web, "/treemaps/assignees"))
DT::saveWidget(dtdata1, "inventors.html")
df = df[, c("priority", "app_name", "count")]
write.csv2(df, "inventors.csv", row.names = F)
df = subset (df, df$count>1)
setwd(paste0(dir))
dtdata1 <- datatable (df, filter = 'top')
DT::saveWidget(dtdata1, "inventors.html")
setwd(paste0(web, "/treemaps/assignees"))
DT::saveWidget(dtdata1, "inventors.html")
df = df[, c("priority", "app_name", "count")]
write.csv2(df, "applicants.csv", row.names = F)
df = subset (df, df$count>1)
setwd(paste0(dir))
dtdata1 <- datatable (df, filter = 'top')
DT::saveWidget(dtdata1, "applicants.html")
setwd(paste0(web))
DT::saveWidget(dtdata1, "applicants.html")
setwd(paste0(web))
writeLines(all, paste0(i, ".html"))
unique (df$region
)
options(stringsAsFactors=FALSE)
library (jsonlite)
library (EconGeo)
library (RColorBrewer)
library (data.table)
library (dplyr)
library(DT)
dir  = "D:/Dropbox/2-private/1-asg/1-production/6-occitanie" # for analysis
dir.regpat = "D:/Dropbox/2-private/1-asg/1-production/_DATA/PATENTS/REGPAT" # for latest regpat version
web = "D:/Dropbox/2-private/PABalland.github.io/bernard-maris-chair/actors"
# load different parts of html
setwd("D:/Dropbox/2-private/1-asg/1-production/_SOURCE/treemaps")
p1 = paste(readLines("part-1.html"), collapse="\n") #before json data
p3 = paste(readLines("part-3-patents-assignee.html"), collapse="\n") #after json data
# read priorities
setwd(paste0(dir))
df = fread ("pctnb-prio.csv", sep = ",", header = T)
# read app info
setwd(dir.regpat)
app = fread ("pctnb-app-reg.csv", sep = ",", header = T)
app$ctry = substr(app$reg_code, 0, 2)
app = app %>% distinct ()
df = inner_join(df, app, by = "pct_nbr")
df$year = as.numeric(substr(df$pct_nbr, 3, 6))
df = subset (df, df$year >= 2017) # select period
df$year = NULL
df$freq = 1
df$ID = paste0(df$priority, df$app_name)
df$count = ave(df$freq, df$ID, FUN = sum)
df = df[, c("priority", "app_name", "count", "ctry")]
df = df %>% distinct ()
df$region = df$priority
df$sum = ave(df$count, df$priority, FUN = sum)
df$share = round (df$count*100/df$sum, digits = 2)
df$count.all = ave(df$count, df$app_name, FUN = sum)
df$sum.all = sum(df$count)
df$shareall = round (df$count.all*100/df$sum.all, digits = 2)
head(df)
for (i in unique (df$region)) {
#i = "Head-up displays"
sub = subset (df, df$region == i)
sub$id = sub$app_name
sub$value = sub$count
sub$color = "lightblue"
sub$color[sub$ctry == "CN"] = "orange"
sub$color[sub$ctry == "US"] = "red"
sub$color[sub$ctry == "JP"] = "yellow"
sub$color[sub$ctry == "DE"] = "green"
sub$color[sub$ctry == "FR"] = "blue"
sub$color[sub$ctry == "KR"] = "lightgreen"
sub$color[sub$ctry == "UK"] = "lightred"
sub$color[sub$ctry == "SE"] = "lightorange"
sub$color[sub$ctry == "CA"] = "lightgrey"
sub$color[sub$ctry == "NL"] = "black"
sub$color[sub$ctry == "IL"] = "grey"
sub$parent = sub$ctry
sub$rca = 0
sub = unique(sub[,  c("parent", "id", "value", "color", "share", "rca", "shareall", "ctry")])
sub = sub[complete.cases(sub),]
p2 = toJSON(sub)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir))
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
writeLines(all, paste0(i, ".html"))
setwd(paste0(web))
writeLines(all, paste0(i, ".html"))
}
df = df[, c("priority", "app_name", "count")]
write.csv2(df, "applicants.csv", row.names = F)
df = subset (df, df$count>1)
setwd(paste0(dir))
dtdata1 <- datatable (df, filter = 'top')
DT::saveWidget(dtdata1, "applicants.html")
setwd(paste0(web))
DT::saveWidget(dtdata1, "applicants.html")
head(df)
View(df)
