##
for (i in unique (df$Industry)) {
#i = "Drenthe"
df = subset (df.full, df.full$Industry == i)
df$Industry = NULL
# add variables
df$id = df$Region
df$value = df$Count
df$name = df$name.english
var = c("parent", "id", "value", "color", "share", "name")
df = unique(df[, var])
df = df[complete.cases(df),]
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "-", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
r=i
p2 = toJSON(df)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir, "3-outputs/treemaps-techs"))
writeLines(all, paste0(r, ".html"))
setwd(paste0(dir2, "/treemaps-techs"))
writeLines(all, paste0(r, ".html"))
}
options(stringsAsFactors=FALSE)
library(jsonlite)
library(EconGeo)
library(RColorBrewer)
dir  = "D:/Dropbox/2-private/1-asg/1-production/1-srip-chapter/" # for analysis
dir2 = "D:/Dropbox/2-private/PABalland.github.io/asg/srip"
# load different parts of html
setwd(paste0(dir, "3-outputs/treemaps-techs/_source"))
p1 = paste(readLines("part-1.html"), collapse="\n") #before json data
p3 = paste(readLines("part-3.html"), collapse="\n") #after json data
# Read bimodal
setwd(paste0(dir, "2-analysis"))
df = as.matrix(read.csv2("1-bimodal-pat-p4.csv",
header = T,
check.names = F,
row.names = 1))
df = get.list (df)
# extract s3 fields
# read crosswalk
setwd(paste0(dir, "1-data"))
d = read.csv("0-S3-CPC.csv", sep = ";", check.names = F)
colnames (d) = c("KIA",	"S3",	"CPC",	"Description")
s3 = unique (d[, c("KIA",	"S3")])
s3$id = as.numeric(factor (unique (s3$S3)))
df = merge (df, s3, by.x = "Industry", by.y = "S3")
#
# back to higher level
#
df = df[, c("Region", "KIA", "Count")]
df = get.matrix (df)
df = get.list (df)
df$id = as.numeric(factor (unique (df$Region)))
df$parent = substr(df$Region, 0, 2)
df$color[df$parent == "AT"] = "lightgreen"
df$color[df$parent == "BE"] = "black"
df$color[df$parent == "BG"] = "white"
df$color[df$parent == "CH"] = "purple"
df$color[df$parent == "CY"] = "white"
df$color[df$parent == "CZ"] = "white"
df$color[df$parent == "DE"] = "yellow"
df$color[df$parent == "DK"] = "brown"
df$color[df$parent == "EE"] = "cyan"
df$color[df$parent == "EL"] = "darkred"
df$color[df$parent == "ES"] = "pink"
df$color[df$parent == "FI"] = "lightpink"
df$color[df$parent == "FR"] = "blue"
df$color[df$parent == "HR"] = "honeydew"
df$color[df$parent == "HU"] = "black"
df$color[df$parent == "IE"] = "green"
df$color[df$parent == "IS"] = "firebrick4"
df$color[df$parent == "IT"] = "lightblue"
df$color[df$parent == "LT"] = "deeppink"
df$color[df$parent == "LU"] = "gold"
df$color[df$parent == "LV"] = "magenta"
df$color[df$parent == "MT"] = "lawngreen"
df$color[df$parent == "NL"] = "orange"
df$color[df$parent == "NO"] = "lightorange"
df$color[df$parent == "PL"] = "darkgrey"
df$color[df$parent == "PT"] = "lightpurple"
df$color[df$parent == "RO"] = "red"
df$color[df$parent == "SE"] = "lightred"
df$color[df$parent == "SI"] = "grey"
df$color[df$parent == "SK"] = "white"
df$color[df$parent == "UK"] = "red"
df$Region = iconv(df$Region, to = 'ASCII//TRANSLIT')
df$Industry = iconv(df$Industry, to = 'ASCII//TRANSLIT')
df$parent = iconv(df$parent, to = 'ASCII//TRANSLIT')
df$sum = ave(df$Count, df$Industry, FUN = sum)
df$share = round (df$Count*100/df$sum, digits = 2)
df$Region = as.character (df$Region)
### get regions names
setwd("D:/Dropbox/2-private/1-asg/1-production/_DATA/d3-maps")
nuts.d3 = read.csv2("unique-nuts2-d3maps.csv")
df$Region[df$Region=="UKI1"] = "UKI3"
df$Region[df$Region=="UKI2"] = "UKI5"
df2 = subset (df, df$Region == "UKI3")
df2$Region[df2$Region=="UKI3"] = "UKI4"
df = rbind (df, df2)
df2 = subset (df, df$Region == "UKI5")
df2$Region[df2$Region=="UKI5"] = "UKI6"
df = rbind (df, df2)
df2 = subset (df, df$Region == "UKI5")
df2$Region[df2$Region=="UKI5"] = "UKI7"
df = rbind (df, df2)
df2 = subset (df, df$Region == "IS01")
df2$Region[df2$Region=="IS01"] = "IS00"
df = rbind (df, df2)
df = merge (df, nuts.d3, by.x = "Region", by.y = "nuts2")
df.full = df
##
for (i in unique (df$Industry)) {
#i = "Drenthe"
df = subset (df.full, df.full$Industry == i)
df$Industry = NULL
# add variables
df$id = df$Region
df$value = df$Count
df$name = df$name.english
var = c("parent", "id", "value", "color", "share", "name")
df = unique(df[, var])
df = df[complete.cases(df),]
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "-", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
r=i
p2 = toJSON(df)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir, "3-outputs/treemaps-techs"))
writeLines(all, paste0(r, ".html"))
setwd(paste0(dir2, "/treemaps-techs"))
writeLines(all, paste0(r, ".html"))
}
options(stringsAsFactors=FALSE)
library(jsonlite)
library(EconGeo)
library(RColorBrewer)
dir  = "D:/Dropbox/2-private/1-asg/1-production/1-srip-chapter/" # for analysis
dir2 = "D:/Dropbox/2-private/PABalland.github.io/asg/srip"
# load different parts of html
setwd(paste0(dir, "3-outputs/treemaps-techs/_source"))
p1 = paste(readLines("part-1.html"), collapse="\n") #before json data
p3 = paste(readLines("part-3.html"), collapse="\n") #after json data
# Read bimodal
setwd(paste0(dir, "2-analysis"))
df = as.matrix(read.csv2("1-bimodal-pat-p4.csv",
header = T,
check.names = F,
row.names = 1))
df = get.list (df)
# extract s3 fields
# read crosswalk
setwd(paste0(dir, "1-data"))
d = read.csv("0-S3-CPC.csv", sep = ";", check.names = F)
colnames (d) = c("KIA",	"S3",	"CPC",	"Description")
s3 = unique (d[, c("KIA",	"S3")])
s3$id = as.numeric(factor (unique (s3$S3)))
df = merge (df, s3, by.x = "Industry", by.y = "S3")
#
# back to higher level
#
df = df[, c("Region", "KIA", "Count")]
df = get.matrix (df)
df = get.list (df)
df$id = as.numeric(factor (unique (df$Region)))
df$parent = substr(df$Region, 0, 2)
df$color[df$parent == "AT"] = "lightgreen"
df$color[df$parent == "BE"] = "black"
df$color[df$parent == "BG"] = "white"
df$color[df$parent == "CH"] = "purple"
df$color[df$parent == "CY"] = "white"
df$color[df$parent == "CZ"] = "white"
df$color[df$parent == "DE"] = "yellow"
df$color[df$parent == "DK"] = "brown"
df$color[df$parent == "EE"] = "cyan"
df$color[df$parent == "EL"] = "darkred"
df$color[df$parent == "ES"] = "pink"
df$color[df$parent == "FI"] = "lightpink"
df$color[df$parent == "FR"] = "blue"
df$color[df$parent == "HR"] = "honeydew"
df$color[df$parent == "HU"] = "black"
df$color[df$parent == "IE"] = "green"
df$color[df$parent == "IS"] = "firebrick4"
df$color[df$parent == "IT"] = "lightblue"
df$color[df$parent == "LT"] = "deeppink"
df$color[df$parent == "LU"] = "gold"
df$color[df$parent == "LV"] = "magenta"
df$color[df$parent == "MT"] = "lawngreen"
df$color[df$parent == "NL"] = "orange"
df$color[df$parent == "NO"] = "lightorange"
df$color[df$parent == "PL"] = "darkgrey"
df$color[df$parent == "PT"] = "lightpurple"
df$color[df$parent == "RO"] = "red"
df$color[df$parent == "SE"] = "lightred"
df$color[df$parent == "SI"] = "grey"
df$color[df$parent == "SK"] = "white"
df$color[df$parent == "UK"] = "red"
df$Region = iconv(df$Region, to = 'ASCII//TRANSLIT')
df$Industry = iconv(df$Industry, to = 'ASCII//TRANSLIT')
df$parent = iconv(df$parent, to = 'ASCII//TRANSLIT')
df$sum = ave(df$Count, df$Industry, FUN = sum)
df$share = round (df$Count*100/df$sum, digits = 2)
df$Region = as.character (df$Region)
### get regions names
setwd("D:/Dropbox/2-private/1-asg/1-production/_DATA/d3-maps")
nuts.d3 = read.csv2("unique-nuts2-d3maps.csv")
df$Region[df$Region=="UKI1"] = "UKI3"
df$Region[df$Region=="UKI2"] = "UKI5"
df2 = subset (df, df$Region == "UKI3")
df2$Region[df2$Region=="UKI3"] = "UKI4"
df = rbind (df, df2)
df2 = subset (df, df$Region == "UKI5")
df2$Region[df2$Region=="UKI5"] = "UKI6"
df = rbind (df, df2)
df2 = subset (df, df$Region == "UKI5")
df2$Region[df2$Region=="UKI5"] = "UKI7"
df = rbind (df, df2)
df2 = subset (df, df$Region == "IS01")
df2$Region[df2$Region=="IS01"] = "IS00"
df = rbind (df, df2)
df = merge (df, nuts.d3, by.x = "Region", by.y = "nuts2")
df.full = df
##
for (i in unique (df$Industry)) {
#i = "Drenthe"
df = subset (df.full, df.full$Industry == i)
df$Industry = NULL
# add variables
df$id = df$Region
df$value = df$Count
df$name = df$name.english
var = c("parent", "id", "value", "color", "share", "name")
df = unique(df[, var])
df = df[complete.cases(df),]
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "-", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
r=i
p2 = toJSON(df)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir, "3-outputs/treemaps-techs"))
writeLines(all, paste0(r, ".html"))
setwd(paste0(dir2, "/treemaps-techs"))
writeLines(all, paste0(r, ".html"))
}
library(jsonlite)
library (EconGeo)
dir  = "D:/Dropbox/2-private/1-asg/1-production/1-srip-chapter/" # for analysis
dir2 = "D:/Dropbox/2-private/PABalland.github.io/asg/srip"
# load different parts of html
setwd(paste0(dir, "3-outputs/maps/_source"))
p1 = paste(readLines("part-1.html"), collapse="\n") #before json data
p3.ai = paste(readLines("part-3-ai.html"), collapse="\n") #after json data
p3.bio = paste(readLines("part-3-bio.html"), collapse="\n") #after json data
p3.iit = paste(readLines("part-3-iit.html"), collapse="\n") #after json data
setwd("D:/Dropbox/2-private/1-asg/1-production/_DATA/d3-maps")
nuts.d3 = read.csv2("unique-nuts2-d3maps.csv")
setwd(paste0(dir, "2-analysis"))
options(stringsAsFactors=FALSE)
x = get.list(
as.matrix(read.csv2 ("1-bimodal-pat-p4.csv", header = T, row.names = 1,
check.names = F)))
main = c("Artificial intelligence",
"Blockchain", "Quantum computing",
"Batteries", "Hydrogen", "mRNA", "Oncology")
x = subset (x, x$Industry%in% main)
x = merge (x, nuts.d3, by.x  = "Region", by.y = "nuts2")
# remove duplicates in nutsd3
dup = c("HU12", "UKM9", "IE05", "LT02", "PL92")
x = x[!x$nuts2.lfs %in% dup,]
x$name.english = paste0(x$name.english, " (",
x$country, ")")
xs = x
for (i in unique (x$Industry)) {
#i =  "Agriculture, Fisheries & Forestry"
# i = "Analysis of biological materials"
c = subset (xs, xs$Industry == i)
name = i
c = unique (c[, c("Region", "name.english", "Count")])
colnames (c) = c("id", "name", "population")
c = c[complete.cases(c),]
p2 = toJSON(c)
Digital =  c("Artificial intelligence",
"Blockchain", "Quantum computing")
Green = c("Batteries", "Hydrogen")
Health = c("mRNA", "Oncology")
if (i %in% Digital) {
p3 = p3.ai
}
if (i %in% Green){
p3 = p3.bio
}
if (i %in% Health){
p3 = p3.iit
}
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "-", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir, "3-outputs/maps"))
writeLines(all, paste0(i, "-count.html"))
setwd(paste0(dir2, "/maps"))
writeLines(all, paste0(i, "-count.html"))
}
setwd(paste0(dir, "2-analysis"))
options(stringsAsFactors=FALSE)
x = get.list(
as.matrix(read.csv2 ("1-bimodal-pat-p4.csv", header = T, row.names = 1,
check.names = F)))
main = c("Artificial intelligence",
"Blockchain", "Quantum computing",
"Batteries", "Hydrogen", "mRNA", "Oncology")
x = subset (x, x$Industry%in% main)
x = merge (x, nuts.d3, by.x  = "Region", by.y = "nuts2")
# remove duplicates in nutsd3
dup = c("HU12", "UKM9", "IE05", "LT02", "PL92")
x = x[!x$nuts2.lfs %in% dup,]
x$name.english = paste0(x$name.english, " (",
x$country, ")")
xs = x
for (i in unique (x$Industry)) {
#i =  "Agriculture, Fisheries & Forestry"
# i = "Analysis of biological materials"
c = subset (xs, xs$Industry == i)
name = i
c = unique (c[, c("Region", "name.english", "Count")])
colnames (c) = c("id", "name", "population")
c = c[complete.cases(c),]
p2 = toJSON(c)
Digital =  c("Artificial intelligence",
"Blockchain", "Quantum computing")
Green = c("Batteries", "Hydrogen")
Health = c("mRNA", "Oncology")
if (i %in% Digital) {
p3 = p3.ai
}
if (i %in% Green){
p3 = p3.bio
}
if (i %in% Health){
p3 = p3.iit
}
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "-", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir, "3-outputs/maps"))
writeLines(all, paste0(i, "-count.html"))
setwd(paste0(dir2, "/maps"))
writeLines(all, paste0(i, "-count.html"))
}
library(jsonlite)
library (EconGeo)
dir  = "D:/Dropbox/2-private/1-asg/1-production/1-srip-chapter/" # for analysis
dir2 = "D:/Dropbox/2-private/PABalland.github.io/asg/srip"
# load different parts of html
setwd(paste0(dir, "3-outputs/maps/_source"))
p1 = paste(readLines("part-1.html"), collapse="\n") #before json data
p3.ai = paste(readLines("part-3-ai.html"), collapse="\n") #after json data
p3.bio = paste(readLines("part-3-bio.html"), collapse="\n") #after json data
p3.iit = paste(readLines("part-3-iit.html"), collapse="\n") #after json data
setwd("D:/Dropbox/2-private/1-asg/1-production/_DATA/d3-maps")
nuts.d3 = read.csv2("unique-nuts2-d3maps.csv")
setwd(paste0(dir, "2-analysis"))
options(stringsAsFactors=FALSE)
x = get.list(
as.matrix(read.csv2 ("1-bimodal-pat-p4.csv", header = T, row.names = 1,
check.names = F)))
View(x)
options(stringsAsFactors=FALSE)
x = get.list(
as.matrix(read.csv2 ("1-bimodal-pat-p4.csv", header = T, row.names = 1,
check.names = F)))
main = c("Artificial intelligence",
"Blockchain", "Quantum computing",
"Batteries", "Hydrogen", "mRNA", "Oncology")
x = subset (x, x$Industry%in% main)
x = merge (x, nuts.d3, by.x  = "Region", by.y = "nuts2")
# remove duplicates in nutsd3
dup = c("HU12", "UKM9", "IE05", "LT02", "PL92")
x = x[!x$nuts2.lfs %in% dup,]
x$name.english = paste0(x$name.english, " (",
x$country, ")")
c = subset (xs, xs$Industry == i)
name = i
c = unique (c[, c("Region", "name.english", "Count")])
colnames (c) = c("id", "name", "population")
c = c[complete.cases(c),]
c
options(stringsAsFactors=FALSE)
x = get.list(
as.matrix(read.csv2 ("1-bimodal-pat-p4.csv", header = T, row.names = 1,
check.names = F)))
main = c("Artificial intelligence",
"Blockchain", "Quantum computing",
"Batteries", "Hydrogen", "mRNA", "Oncology")
x = subset (x, x$Industry%in% main)
View(x)
x = merge (x, nuts.d3, by.x  = "Region", by.y = "nuts2")
View(x)
View(x)
x$Industry
i = "Quantum computing"
c = subset (xs, xs$Industry == i)
name = i
c = unique (c[, c("Region", "name.english", "Count")])
colnames (c) = c("id", "name", "population")
c = c[complete.cases(c),]
View(c)
p2 = toJSON(c)
Digital =  c("Artificial intelligence",
"Blockchain", "Quantum computing")
Green = c("Batteries", "Hydrogen")
Health = c("mRNA", "Oncology")
setwd(paste0(dir, "2-analysis"))
library(jsonlite)
library (EconGeo)
dir  = "D:/Dropbox/2-private/1-asg/1-production/1-srip-chapter/" # for analysis
dir2 = "D:/Dropbox/2-private/PABalland.github.io/asg/srip"
# load different parts of html
setwd(paste0(dir, "3-outputs/maps/_source"))
p1 = paste(readLines("part-1.html"), collapse="\n") #before json data
p3.ai = paste(readLines("part-3-ai.html"), collapse="\n") #after json data
p3.bio = paste(readLines("part-3-bio.html"), collapse="\n") #after json data
p3.iit = paste(readLines("part-3-iit.html"), collapse="\n") #after json data
setwd("D:/Dropbox/2-private/1-asg/1-production/_DATA/d3-maps")
nuts.d3 = read.csv2("unique-nuts2-d3maps.csv")
setwd(paste0(dir, "2-analysis"))
options(stringsAsFactors=FALSE)
x = get.list(
as.matrix(read.csv2 ("3-RCA-pat-p4.csv", header = T, row.names = 1,
check.names = F)))
main = c("Artificial intelligence",
"Blockchain", "Quantum computing",
"Batteries", "Hydrogen", "mRNA", "Oncology")
x = subset (x, x$Industry%in% main)
x = merge (x, nuts.d3, by.x  = "Region", by.y = "nuts2")
# remove duplicates in nutsd3
dup = c("HU12", "UKM9", "IE05", "LT02", "PL92")
x = x[!x$nuts2.lfs %in% dup,]
x$name.english = paste0(x$name.english, " (",
x$country, ")")
xs = x
for (i in unique (x$Industry)) {
#i =  "Agriculture, Fisheries & Forestry"
# i = "Analysis of biological materials"
c = subset (xs, xs$Industry == i)
name = i
c = unique (c[, c("Region", "name.english", "Count")])
colnames (c) = c("id", "name", "population")
c = c[complete.cases(c),]
p2 = toJSON(c)
Digital =  c("Artificial intelligence",
"Blockchain", "Quantum computing")
Green = c("Batteries", "Hydrogen")
Health = c("mRNA", "Oncology")
if (i %in% Digital) {
p3 = p3.ai
}
if (i %in% Green){
p3 = p3.bio
}
if (i %in% Health){
p3 = p3.iit
}
i = iconv(i, to = 'ASCII//TRANSLIT')
i = gsub(" ", "-", i, fixed = TRUE)
i = gsub("/", "-", i, fixed = TRUE)
i = gsub(",", "-", i, fixed = TRUE)
i = gsub("(", "-", i, fixed = TRUE)
i = gsub(")", "-", i, fixed = TRUE)
i = gsub("--", "-", i, fixed = TRUE)
i = gsub("-.", ".", i, fixed = TRUE)
i = tolower (i)
all = paste (p1, p2, p3, collapse="\n")
setwd(paste0(dir, "3-outputs/maps"))
writeLines(all, paste0(i, "-rca.html"))
setwd(paste0(dir2, "/maps"))
writeLines(all, paste0(i, "-rca.html"))
}
