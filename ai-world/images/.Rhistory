df2$value = df2$count
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir")
library(jsonlite)
# Create a classification vector using %in%
count$parent <- ifelse(count$country %in% eu27_countries, "EU27", "Rest of world")
count$parent <- ifelse(count$country == "United States", "United States", count$parent)
count$parent <- ifelse(count$country == "China", "China", count$parent)
count$parent <- ifelse(count$country == "United Kingdom", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Iceland", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Liechtenstein", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Norway", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Switzerland", "UK + EFTA", count$parent)
df2 = count
df2$id = df2$country
df2$value = df2$count
df2$color[df2$parent == "United States"] = "#8cab79"
df2$color[df2$parent == "China"] = "#365a94"
df2$color[df2$parent == "EU27" ] = "#e28f26"
df2$color[df2$parent == "UK + EFTA"] = "#669999"
df2$color[df2$parent == "Rest of world"] = "#D3D3D3"
df2 = unique(df2[,  c("id", "value", "parent", "color")])
df2 = df2[complete.cases(df2),]
df2$share = round(100*df2$value/(sum(df2$value)),2)
# convert to JSON
p2 = toJSON(df2)
all = paste (p1, p2, p3, collapse="\n")
i = "esir-science"
i = tolower(i)
# save as d3plus
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir")
writeLines(all, paste0(i, ".html"))
# packages & codes
library(jsonlite)
library(dplyr)
library(tidyverse)
library(data.table)
library(jsonlite)
# html source location
setwd("/Users/pierre-alex/Dropbox/1-asg/1-production/3-projects/4-dutch-regions/3-outputs/deliverable-1/treemaps/_source")
p1 = paste(readLines("part-1.html"), collapse="\n") #before json data
p3 = paste(readLines("part-3.html"), collapse="\n") #after json data
# READ NB OF ARTICLES PER PRIOSECTOR - YEAR
setwd("/Users/pierre-alex/Dropbox/1-asg/1-production/3-projects/3-unido/1-data/pub")
df2 = fread ("pub-nb-prio.csv")
df2 = subset (df2, df2$year>=2020)
df2 = subset (df2, df2$year<=2024) # before full scale russian invasion
df2$work_id <- as.numeric(df2$work_id)
# READ WORKS CITIES
setwd("/Users/pierre-alex/Dropbox/1-asg/1-production/1-data/SCIENCE/OPENALEX/publication_location")
geo2 = NULL
i = 2022
for (i in c(2024,2023,2022,2021,2020)){
#for (i in c(2024)){
setwd("/Users/pierre-alex/Dropbox/1-asg/1-production/1-data/SCIENCE/OPENALEX/publication_location")
geo = fread (paste0(i,".csv"))
geo = geo[, c("work_id", "country", "country_code")]
geo = subset (geo, !geo$country == "")
geo$work_id <- as.numeric(geo$work_id)
geo = merge (geo, df2, by = "work_id")
geo2=rbind(geo2,geo)
}
geo2 = unique(geo2)
df = geo2
# count per country
df$freq = 1
df$count = ave(df$freq, paste0(df$country), FUN = sum)
df$count.prio = ave(df$freq, paste0(df$country, df$priority), FUN = sum)
count = df
count$year = NULL
count$work_id = NULL
count$freq=NULL
count = unique (count)
count = subset (count, priority == "Artificial intelligence")
eu27_countries <- c("Austria", "Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Denmark",
"Estonia", "Finland", "France", "Germany", "Greece", "Hungary", "Ireland",
"Italy", "Latvia", "Lithuania", "Luxembourg", "Malta", "Netherlands",
"Poland", "Portugal", "Romania", "Slovakia", "Slovenia", "Spain", "Sweden")
# Create a classification vector using %in%
count$parent <- ifelse(count$country %in% eu27_countries, "EU27", "Rest of world")
count$parent <- ifelse(count$country == "United States", "United States", count$parent)
count$parent <- ifelse(count$country == "China", "China", count$parent)
count$parent <- ifelse(count$country == "United Kingdom", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Iceland", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Liechtenstein", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Norway", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Switzerland", "UK + EFTA", count$parent)
df2 = count
df2$id = df2$country
df2$value = df2$
df2$value2 = df2$count.prio
df2$color[df2$parent == "United States"] = "#8cab79"
df2$color[df2$parent == "China"] = "#365a94"
df2$color[df2$parent == "EU27" ] = "#e28f26"
df2$color[df2$parent == "UK + EFTA"] = "#669999"
df2$color[df2$parent == "Rest of world"] = "#D3D3D3"
df2 = unique(df2[,  c("id", "value", "parent", "color")])
df2 = df2[complete.cases(df2),]
df2$share = round(100*df2$value/(sum(df2$value)),2)
# convert to JSON
p2 = toJSON(df2)
all = paste (p1, p2, p3, collapse="\n")
i = "esir-science"
i = tolower(i)
# save as d3plus
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir")
writeLines(all, paste0(i, ".html"))
df2 = count
df2$id = df2$country
df2$value = df2$
df2$value2 = df2$count.prio
df2$color[df2$parent == "United States"] = "#8cab79"
df2$color[df2$parent == "China"] = "#365a94"
df2$color[df2$parent == "EU27" ] = "#e28f26"
df2$color[df2$parent == "UK + EFTA"] = "#669999"
df2$color[df2$parent == "Rest of world"] = "#D3D3D3"
df2 = unique(df2[,  c("id", "value", "parent", "color", "value2")])
df2 = count
df2$id = df2$country
df2$value = df2$
df2$value2 = df2$count.prio
df2$color[df2$parent == "United States"] = "#8cab79"
df2$color[df2$parent == "China"] = "#365a94"
df2$color[df2$parent == "EU27" ] = "#e28f26"
df2$color[df2$parent == "UK + EFTA"] = "#669999"
df2$color[df2$parent == "Rest of world"] = "#D3D3D3"
df2 = unique(df2[,  c("id", "value", "parent", "color", "value2")])
df2 = count
head(df2)
df2$id = df2$country
df2$value = df2$count
df2$value2 = df2$count.prio
df2$color[df2$parent == "United States"] = "#8cab79"
df2$color[df2$parent == "China"] = "#365a94"
df2$color[df2$parent == "EU27" ] = "#e28f26"
df2$color[df2$parent == "UK + EFTA"] = "#669999"
df2$color[df2$parent == "Rest of world"] = "#D3D3D3"
df2 = unique(df2[,  c("id", "value", "parent", "color", "value2")])
df2 = count
df2$id = df2$country
df2$value = df2$count
df2$value2 = df2$count.prio
df2$color[df2$parent == "United States"] = "#8cab79"
df2$color[df2$parent == "China"] = "#365a94"
df2$color[df2$parent == "EU27" ] = "#e28f26"
df2$color[df2$parent == "UK + EFTA"] = "#669999"
df2$color[df2$parent == "Rest of world"] = "#D3D3D3"
df2 = unique(df2[,  c("id", "value", "parent", "color", "value2")])
df2 = df2[complete.cases(df2),]
df2$share = round(100*df2$value/(sum(df2$value)),2)
# convert to JSON
p2 = toJSON(df2)
all = paste (p1, p2, p3, collapse="\n")
i = "esir-science"
i = tolower(i)
# save as d3plus
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir")
writeLines(all, paste0(i, ".html"))
View(df2)
head(country)
head(count)
count = df
count$year = NULL
count$work_id = NULL
count$freq=NULL
count = unique (count)
count = subset (count, priority == "Artificial intelligence")
eu27_countries <- c("Austria", "Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Denmark",
"Estonia", "Finland", "France", "Germany", "Greece", "Hungary", "Ireland",
"Italy", "Latvia", "Lithuania", "Luxembourg", "Malta", "Netherlands",
"Poland", "Portugal", "Romania", "Slovakia", "Slovenia", "Spain", "Sweden")
# Create a classification vector using %in%
count$parent <- ifelse(count$country %in% eu27_countries, "EU27", "Rest of world")
count$parent <- ifelse(count$country == "United States", "United States", count$parent)
count$parent <- ifelse(count$country == "China", "China", count$parent)
count$parent <- ifelse(count$country == "United Kingdom", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Iceland", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Liechtenstein", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Norway", "UK + EFTA", count$parent)
count$parent <- ifelse(count$country == "Switzerland", "UK + EFTA", count$parent)
count$country <- ifelse(count$parent == "Rest of world", "Rest of world", count$country)
df2 = count
df2$id = df2$country
df2$value = df2$count
df2$value2 = df2$count.prio
df2$color[df2$parent == "United States"] = "#8cab79"
df2$color[df2$parent == "China"] = "#365a94"
df2$color[df2$parent == "EU27" ] = "#e28f26"
df2$color[df2$parent == "UK + EFTA"] = "#669999"
df2$color[df2$parent == "Rest of world"] = "#D3D3D3"
df2 = unique(df2[,  c("id", "value", "parent", "color", "value2")])
df2 = df2[complete.cases(df2),]
df2$share = round(100*df2$value/(sum(df2$value)),2)
# convert to JSON
p2 = toJSON(df2)
all = paste (p1, p2, p3, collapse="\n")
i = "esir-science"
i = tolower(i)
# save as d3plus
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir")
writeLines(all, paste0(i, ".html"))
View(df2)
2051987/5
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir/_archives/op-ed-forge-ahead")
df <- read.csv("organizations-6-8-2024.csv", row.names = NULL)
df <- read.csv("companies-6-8-2024.csv", row.names = NULL)
df$value = df$Total.Funding.Amount.Currency..in.USD.
df$parent = df$Headquarters.Location
df$id = df$Organization.Name
# Convert the data frame to JSON format
json_data <- toJSON(df)
# Write the JSON data to a file
write(json_data, "eu-ai.json")
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir/_archives/op-ed-forge-ahead")
# Read the CSV file into a data frame
# data source: top Companies in the World as of Jul. 01, 2023
# above 1 billion market cap
# https://disfold.com/sector/technology/companies/?page=19
df <- read.csv("companies-6-8-2024.csv", row.names = NULL)
# Find the max number of splits
max_splits <- max(sapply(split_column, length))
library(jsonlite)
library(tidyr)
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir/_archives/op-ed-forge-ahead")
# Read the CSV file into a data frame
# data source: top Companies in the World as of Jul. 01, 2023
# above 1 billion market cap
# https://disfold.com/sector/technology/companies/?page=19
df <- read.csv("companies-6-8-2024.csv", row.names = NULL)
# Find the max number of splits
max_splits <- max(sapply(split_column, length))
View(df)
# Pad shorter vectors with NA
split_column_padded <- lapply(split_column, function(x) {
c(x, rep(NA, max_splits - length(x)))
})
# Now, create the matrix
split_matrix <- do.call(rbind, split_column_padded)
df <- read.csv("companies-6-8-2024.csv", row.names = NULL)
split_column <- strsplit(as.character(df$split_column), ",")
# Find the max number of splits
max_splits <- max(sapply(split_column, length))
split_column <- strsplit(as.character(df$Headquarters.Location), ",")
# Find the max number of splits
max_splits <- max(sapply(split_column, length))
# Pad shorter vectors with NA
split_column_padded <- lapply(split_column, function(x) {
c(x, rep(NA, max_splits - length(x)))
})
# Now, create the matrix
split_matrix <- do.call(rbind, split_column_padded)
# Convert the matrix to a data frame
split_df <- as.data.frame(split_matrix)
# Name the new columns
colnames(split_df) <- c("city", "region", "country")
split_df$country[split_df$country == " City of"] = " United Kingdom"
split_df = split_df[,-4]
# Drop the old third column and add new columns to the data frame
df <- df[,-3]
df <- cbind(df, split_df)
#df = fromJSON("crunchbase2.json")
df$parent = "Other"
View(df)
df$country[df$country == "City of"] = "United Kingdom"
df$country <- gsub("^ +", "", df$country)
df$parent[df$country == "China"] = "China" # Muted, medium-dark shade of blue
df$parent[df$country == "United States"] = "United States" # Subdued, medium olive green
df$parent[df$country == "France"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Germany"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Spain"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "United Kingdom"] = "Europe +" # Subdued, medium olive green
df$parent[df$country == "Finland"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Belgium"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Estonia"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Norway"] = "Europe +" # Subdued, medium olive green
df$parent[df$country == "Switzerland"] = "Europe +" # Subdued, medium olive green
df$parent[df$country == "Ireland"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "The Netherlands"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Portugal"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Sweden"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Hungary"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Greece"] = "Europe" # Subdued, medium olive green
df$color = "lightgrey"
df$color[df$parent == "China"] = "#365a94" # Muted, medium-dark shade of blue
df$color[df$parent == "United States"] = "#8cab79" # Subdued, medium olive green
df$color[df$parent == "Europe"] = "#e28f26" # Subdued, medium olive green
df$color[df$parent == "Europe +"] = "#669999" # Subdued, medium olive green
df$value = df$Total.Funding.Amount.Currency..in.USD.
df$id = df$Organization.Name
#df$exit = nchar(df$Exit.Date)
#df = subset (df, df$exit==0)
# Convert the data frame to JSON format
json_data <- toJSON(df)
# Write the JSON data to a file
write(json_data, "crunchbase4.json")
head(df)
library(jsonlite)
library(tidyr)
setwd("~/Dropbox/1-asg/1-production/3-projects/0-esir/_archives/op-ed-forge-ahead")
# Read the CSV file into a data frame
# data source: top Companies in the World as of Jul. 01, 2023
# above 1 billion market cap
# https://disfold.com/sector/technology/companies/?page=19
df <- read.csv("companies-6-8-2024.csv", row.names = NULL)
split_column <- strsplit(as.character(df$Headquarters.Location), ",")
# Find the max number of splits
max_splits <- max(sapply(split_column, length))
# Pad shorter vectors with NA
split_column_padded <- lapply(split_column, function(x) {
c(x, rep(NA, max_splits - length(x)))
})
# Now, create the matrix
split_matrix <- do.call(rbind, split_column_padded)
# Convert the matrix to a data frame
split_df <- as.data.frame(split_matrix)
# Name the new columns
colnames(split_df) <- c("city", "region", "country")
split_df$country[split_df$country == " City of"] = " United Kingdom"
split_df = split_df[,-4]
# Drop the old third column and add new columns to the data frame
df <- df[,-3]
df <- cbind(df, split_df)
#df = fromJSON("crunchbase2.json")
df$parent = "Other"
df$country[df$country == "City of"] = "United Kingdom"
df$country <- gsub("^ +", "", df$country)
df$parent[df$country == "China"] = "China" # Muted, medium-dark shade of blue
df$parent[df$country == "United States"] = "United States" # Subdued, medium olive green
df$parent[df$country == "France"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Germany"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Spain"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "United Kingdom"] = "Europe +" # Subdued, medium olive green
df$parent[df$country == "Finland"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Belgium"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Estonia"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Norway"] = "Europe +" # Subdued, medium olive green
df$parent[df$country == "Switzerland"] = "Europe +" # Subdued, medium olive green
df$parent[df$country == "Ireland"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "The Netherlands"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Portugal"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Sweden"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Hungary"] = "Europe" # Subdued, medium olive green
df$parent[df$country == "Greece"] = "Europe" # Subdued, medium olive green
df$color = "lightgrey"
df$color[df$parent == "China"] = "#365a94" # Muted, medium-dark shade of blue
df$color[df$parent == "United States"] = "#8cab79" # Subdued, medium olive green
df$color[df$parent == "Europe"] = "#e28f26" # Subdued, medium olive green
df$color[df$parent == "Europe +"] = "#669999" # Subdued, medium olive green
df$value = df$Total.Funding.Amount..in.USD.
df$id = df$Organization.Name
#df$exit = nchar(df$Exit.Date)
#df = subset (df, df$exit==0)
# Convert the data frame to JSON format
json_data <- toJSON(df)
# Write the JSON data to a file
write(json_data, "crunchbase4.json")
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
library(jsonlite)
# Read the CSV file
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read_csv("country.csv")
# Install necessary packages
#install.packages("readr")
#install.packages("jsonlite")
# Load the libraries
#library(readr)
library(jsonlite)
# Read the CSV file
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read_csv("countries.csv")
country_data <- read_delim("countries.csv", delim = "\t")
View(country_data)
is.numeric(country_data$`Area in km2`)
is.numeric(country_data$`Population`)
write.csv(country_data, "countries2.csv", row.names = F)
country_data$...10=NULL
country_data$...11=NULL
country_data$...12=NULL
country_data$...13=NULL
country_data$...14=NULL
write.csv(country_data, "countries2.csv", row.names = F)
is.unique(country_data$ISO_3166_alpha2)
unique(country_data$ISO_3166_alpha2)
country <- read_csv("countries2.csv")
country <- read.csv("countries2.csv")
View(country)
country <- read.csv("countries.csv")
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
country <- toJSON(country_data, pretty = TRUE)
write(country, file = "country.json")
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
country <- toJSON(country_data, pretty = TRUE)
write(country, file = "countries.json")
View(country_data)
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
View(country)
View(country)
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
country <- toJSON(country_data, pretty = F)
write(country, file = "countries.json")
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country_data <- read.csv("countries.csv")
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country_data <- read.csv("countries.csv")
# Remove carriage return characters from all character columns
country_data[] <- lapply(country_data, function(x) {
if (is.character(x)) gsub("\r", "", x) else x
})
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
country <- toJSON(country_data, pretty = T)
write(country, file = "countries.json")
c1 = fromJSON("countries.json")
c1 = fromJSON("countries.json")
View(c1)
write.csv(c1, "countries2.csv", row.names = F)
country <- read.csv("countries2.csv")
country <- toJSON(country_data, pretty = T)
write(country, file = "countries2.json")
country <- read.csv("countries2.csv")
country <- read.csv("countries2.csv")
View(country)
country <- toJSON(country_data, pretty = T)
country <- read.csv("countries2.csv")
country <- toJSON(country, pretty = T)
write(country, file = "countries2.json")
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
country <- toJSON(country_data, pretty = T)
write(country, file = "countries.json")
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
country <- toJSON(country, pretty = T)
write(country, file = "countries.json")
library(jsonlite)
setwd("~/Dropbox/1-asg/1-production/1-data/GEO")
country <- read.csv("countries.csv")
country <- toJSON(country, pretty = T)
write(country, file = "countries.json")
country <- fromJSON("countries.json")
country <- fromJSON("country_shapes.geojson")
View(country)
library(maps)
install.packages("maps")
library(maps)
map("france")
base=read.csv(
"http://freakonometrics.free.fr/popfr19752010.csv",
header=TRUE)
head(base)
View(base)
base$city = paste0(base$article, " ", base$com_nom)
head(base)
setwd("/Users/pierre-alex/Dropbox/PABalland.github.io/geo")
library(maps)
map("france")
#library(maps)
#map("france")
base=read.csv("http://freakonometrics.free.fr/popfr19752010.csv",header=TRUE)
base$city = paste0(base$article, " ", base$com_nom)
base$country = "France"
base$value = log(base$pop_2010+1)
base$population = base$pop_2010
base$latitude = base$lat
base$longitude = base$long
base$slug = paste0(base$reg, base$dep, base$com)
setwd("/Users/pierre-alex/Dropbox/PABalland.github.io/geo")
write(base, file = "france-communes.json")
setwd("/Users/pierre-alex/Dropbox/PABalland.github.io/geo")
country <- toJSON(base, pretty = T)
write(country, file = "france-communes.json")
base2 = base[1:100,]
View(base2)
base2 = base[-order(base$population),]
base2 = base2[1:100,]
View(base2)
base2 = base[-order(base$population),]
base2 = complete.cases(base2)
base2 = base[-order(base$population),]
base2 = complete.cases(base2)
base2 = base2[1:100,]
base2 = base[-order(base$population),]
base2 = base2[complete.cases(base2)]
base2 = base2[1:100,]
base2 = base[-order(base$population),]
base2 = base2[complete.cases(base2),]
base2 = base2[1:100,]
View(base2)
base2 = base[-order(base$population),]
base2 = base[order(-base$population),]
base2 = base[order(-base$population),]
base2 = base2[complete.cases(base2),]
base2 = base2[1:100,]
View(base2)
View(base2)
country <- toJSON(base2, pretty = T)
write(country, file = "france-communes2.json")
